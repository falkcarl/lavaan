\name{lci}
\alias{lci}
\title{Likelihood-based confidence intervals}
\description{Obtains likelihood-based intervals from fitted lavaan model}
\usage{
lci(object, label, level=.95, bound=c("lower","upper"),
              optimizer="Rsolnp",
              ci.method="NealeMiller1997",
              start=NULL,diff.method="default",Dtol=.05,
              iterlim=25,reoptimize=FALSE)
}
\arguments{
\item{object}{An object of class \code{\linkS4class{lavaan}}.}
\item{label}{A string corresponding to a label for the parameter estimate or quantity computed with the \code{":="} operator (e.g., see \code{\link{model.syntax}}). Valid labels for the current model can be inspected using \code{\link{parTable}}.}
\item{level}{Confidence level required (e.g., .95 for 95\% CI).}
\item{bound}{\code{"lower"} for lower bound, \code{"upper"} for upper bound, or \code{c("lower","upper")} for both.}
\item{optimizer}{This controls the optimizer used for finding upper and lower bounds, if an algorithm such as a modified version of that by Neale & Miller (1997) is employed. The default \code{"Rsolnp"} employs \code{\link[Rsolnp]{solnp}} to optimize, which has been found in simulations to be slow but stable (Falk, under review). Note that further changes in the underlying optimization routine may be forthcoming to increase the speed and/or accuracy of the intervals. Other options for choice of optimizer include \code{"optim"} and \code{"nlminb"}, but may not consistently yield valid intervals.}
\item{ci.method}{This option controls the algorithm used to find upper and lower bounds. Although Pek and Wu (2015) offer a number of algorithms, the current version of this code implements only two that have been widely tested and found to consistently provide valid intervals. \code{"NealeMiller1997"}, the default, corresponds to a modified version of Neale & Miller (1997) as detailed and studied by Falk (under review). \code{"bisect"} employs a bisection algorithm. Other faster or more accurate algorithms are possible (e.g., Wu & Neale, 2012), but have not yet been implemented due in part to difficulty in optimization.}
\item{start}{ (Not yet supported). An optional vector used as starting values for the parameter(s) of interest, which could be different than those in the initially fitted model. Currently point estimates in the fitted model are used.}
\item{diff.method}{Passed as the \code{"method"} argument to \code{\link{lavTestLRT}} to compute difference tests used to find CI boundaries.}
\item{Dtol}{(Not yet supported). Tolerance level for difference test; if difference test at a boundary is not within this amount of the critical value, a future version of this function may print a warning, attempt re-optimization, or otherwise attempt to diagnose the problem.}
\item{iterlim}{Number of iterations to perform if \code{"bisect"} is used as the estimation algorithm.}
\item{reoptimize}{(Not yet supported). Future version of this code may attempt re-optimization if it appears that a proper upper/lower boundary is not found.}
}
\author{Carl F. Falk}
\details{Likelihood-based confidence intervals (LCIs; e.g., Neale & Miller, 1997; Pek & Wu, 2015) are asymptotically equivalent to the Wald-based intervals (based on standard errors of parameter estimates) that can be generated by \code{\link{parameterEstimates}}. LCIs, however, may yield more accurate coverage rates in finite samples (e.g., Falk, under review). LCIs are based on inverting likelihood ratio tests (colloquially referred to as chi-square difference tests) used in model comparisons. That is, the lower/upper boundaries of LCIs are the point at which a likelihood ratio test would become exactly significant. Software to produce LCIs for structural equation models is rare, with \emph{Mx} and \emph{OpenMx} being few known alternatives. LCIs are also more computationally intensive than Wald-based intervals and the speed/accuracy of such algorithms is a topic of current research (Pek & Wu, 2015).

This function is an initial implementation of LCIs for \code{lavaan} and is subject to change. In particular, the initially written estimation code assumed no internal access to \code{lavaan} functions and may be re-written for improved computational speed and accuracy. Although every effort has been made to ensure that this function performs as expected, bug reports and additional suggestions for improvement are encouraged. Note that warnings are common and expected as the optimizer may try values for the quantity of interest that may cause difficulty by \code{lavaan}. These are not yet suppressed by the current version of this code.

The default algorithm ("NealeMiller1997") is a modified version of Neale & Miller's (1997) algorithm by Falk (under review) and is detailed therein. This method, along with \code{"Rsolnp"} were employed by Falk (under review) and were tested in several simulation studies.

The "bisect" algorithm proceeds one boundary at a time - first trying to find a value for the quantity of interest beyond the upper/lower boundary. This initial search for a boundary is based in part on use of the standard error for the quantity of interest. If/when such a value is found, bisection is used to find the boundary at which the difference test becomes significant.

It is possible for LCI estimation for one boundary to fail if there is insufficient information (i.e., a small sample size, few items). Diagnostics to examine the profile log-likelihood and or a profile of the difference test may be forthcoming. Currently, the function does return the obtained difference test at each of the boundaries.

In theory, this function can compute LCIs using any estimator and difference test that \code{\link{lavTestLRT}} can properly compute and that follows a chi-square reference distribution. However, to date use of only continuous data with \code{estimator="ML"}, or \code{estimator="MLM"} and the "robust" difference test of Satorra (2000; by using \code{diff.method="satorra.2000"}) have been thoroughly tested and found to perform consistently well.

}
\value{
A list possibly containing the following:

\item{est}{A point estimate for the quantity of interest specified by \code{label}.}
\item{crit}{Critical chi-square value of the difference test sought for the upper/lower boundaries. If \code{diff.method="satorra.2000"}, this may differ from that implied by \code{level} due to use of the scaling constant. That is, the scaling constant used by Satorra (2000) implies a different critical chi-square value to adjust for non-normality.}
\item{lower}{The lower CI boundary.}
\item{convlower}{A convergence code returned by the optimizer at the lower CI boundary. 0 is expected if there were no major problems with optimization.}
\item{Dlower}{Chi-square difference test actually obtained at the lower boundary.}
\item{upper}{The upper CI boundary.}
\item{convupper}{A convergence code returned by the optimizer at the upper CI boundary. 0 is expected if there were no major problems with optimization.}
\item{Dupper}{Chi-square difference test actually obtained at the upper boundary.}

}

\references{
Falk, C. F. (under review). \emph{Are robust standard errors the best approach for
interval estimation with non-normal data in structural equation modeling?}

Neale, M. C., & Miller, M. B. (1997). The use of likelihood-based confidence intervals
in genetic models. \emph{Behavior Genetics, 27,} 113--120.

Pek, J., & Wu, H. (2015). Profile likelihood-based confidence intervals and regions 
for structural equation models. \emph{Psychometrika, 80,} 1123--1145.

Satorra, A. (2000). Scaled and adjusted restricted tests in multi-saple analysis of
moment structures. In D. D. H. Heijmans, D. S. G. Pollock, & A. Satorra (Eds.),
\emph{Innovations in multivariate statistical analysis: A fetschrift for Heinz Neudecker}
(pp. 223--247). Dordrecht, The Netherlands: Kluwer Academic.

Wu, H., & Neale, M. C. (2012). Adjusted confidence intervals for a bounded parameter.
\emph{Behavior Genetics, 42,} 886--898.
}

\examples{
\dontrun{
# fit the Holzinger and Swineford (1939) example
# label for second loading (l2)
# label for factor variance (vVis)
# label for error variances (psi1 and psi2)
# and computed standardized loadings (lam1 and lam2)
HS.model <- ' visual  =~ x1 + l2*x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 
              
              visual~~ vVis*visual
              x1 ~~ psi1*x1
              x2 ~~ psi2*x2
              lam1 := 1/sqrt(1^2*vVis + psi1)*sqrt(vVis)
              lam2 := l2/sqrt(l2^2*vVis + psi2)*sqrt(vVis)'

fit <- cfa(HS.model, data=HolzingerSwineford1939, se="none")

# CIs for second loading
lci(fit,"l2")

# CIs for standardized loadings
lci(fit, "lam1")
lci(fit, "lam2")

# CIs using "robust" difference test of Satorra (2000)
# meanstructure=TRUE appears to be required for robust LCIs to work properly
fit.robust <- cfa(HS.model, data=HolzingerSwineford1939, se="none",
  estimator="MLM", meanstructure=TRUE)

# CIs for second loading
lci(fit.robust,"l2",diff.method="satorra.2000")

# CIs for standardized loadings
lci(fit.robust, "lam1",diff.method="satorra.2000")
lci(fit.robust, "lam2",diff.method="satorra.2000")
}
}
